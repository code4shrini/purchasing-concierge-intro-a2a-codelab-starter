# .env

# --- ChromaDB Configuration (for mcp_chroma_server.py) ---
# Choose one:
# CHROMA_CLIENT_TYPE=ephemeral
#CHROMA_CLIENT_TYPE=persistent
#CHROMA_DATA_DIR=./chroma_data_storage # Directory for persistent ChromaDB data

# If using http client, configure the host and port where your ChromaDB server runs:
 CHROMA_CLIENT_TYPE=http
 CHROMA_HOST=localhost
 CHROMA_PORT=8000

# --- LLM Configuration (for adk_agent.py) ---
# Example for OpenAI
# OPENAI_API_KEY="YOUR_OPENAI_API_KEY"

# Example for Ollama (e.g., running Gemma locally)
#OLLAMA_API_BASE="http://localhost:11434"
 LITELLM_MODEL="gemini/gemini-1.5-flash" #"ollama/gemma-3:12b" # This might be used by LiteLlm internally, depending on your LiteLlm setup
 GOOGLE_APPLICATION_CREDENTIALS=/Users/sudeepshrinivasan/env/sa-key.json
 # Replace the `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION` values
# with appropriate values for your project.
export GOOGLE_CLOUD_PROJECT=wise-cycling-462813-u7
export GOOGLE_CLOUD_LOCATION=global
export GOOGLE_GENAI_USE_VERTEXAI=True
GOOGLE_API_KEY="AIzaSyBM-xk-mCCnLf1ZtBhgTw8XFFwZPPrf0jI"